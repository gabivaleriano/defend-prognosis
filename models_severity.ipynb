{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import shap\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, make_scorer, roc_auc_score, recall_score\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#algorithms\n",
    "algorithms = {\"GB\" : (GradientBoostingClassifier(random_state=0), \n",
    "                      {\"n_estimators\": [100,200,500],  'learning_rate': [0.05, 0.1], \"max_depth\": [4,6,10]})}\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sirio\n",
      "testando\n",
      "testando\n",
      "testando\n",
      "testando\n",
      "testando\n",
      "testando\n",
      "testando\n",
      "testando\n",
      "testando\n",
      "testando\n"
     ]
    }
   ],
   "source": [
    "#hosp1\n",
    "data = pd.read_csv(\"hosp1.csv\")\n",
    "\n",
    "#isolate the target variable \n",
    "X = data.drop(columns = [\"Severity\"])\n",
    "y = data.Severity\n",
    "\n",
    "#sets 3 folders to select the best hyper-parameters by cross validation within the grid search \n",
    "gskf = StratifiedKFold(n_splits=3, shuffle=True, random_state=17) \n",
    "\n",
    "#sets balanced accuracy to choose the best hyper-parameters within the grid search\n",
    "perf = balanced_accuracy_score\n",
    "\n",
    "#sets 10 folders for cross validation \n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=17)  \n",
    "\n",
    "#will store the recall values of each fold\n",
    "score = {}\n",
    "for algorithm in algorithms.keys():\n",
    "    score[algorithm] = []\n",
    "\n",
    "#will store the auc values of each fold\n",
    "auc_score = {}\n",
    "for algorithm in algorithms.keys():\n",
    "    auc_score[algorithm] = []\n",
    "    \n",
    "#for each algorithm and its dictionary of hyperparameters to be tested\n",
    "for algorithm, (clf, parameters) in algorithms.items():\n",
    "\n",
    "    #for each of the 10 folds       \n",
    "    for train, test in kf.split(X, y):\n",
    "        \n",
    "        #splits data into training and testing\n",
    "        X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "        y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "\n",
    "        #will store the y_predicted and y_true \n",
    "        y_pred = [] \n",
    "        y_true =  [] \n",
    "\n",
    "        #as the classes are umbalanced randomly undersample the majority class repeating 10 times to avoid bias \n",
    "        for j in range(0,10):\n",
    "\n",
    "            #impute missing values with the mean of the 3 nearest neighbors\n",
    "            imputer = KNNImputer(n_neighbors=3)\n",
    "            imputer.fit(X_train)\n",
    "            X_train = imputer.transform(X_train)\n",
    "            X_test = imputer.transform(X_test)\n",
    "\n",
    "            #balance the classes by randomly undersampling the majority class\n",
    "            under = RandomUnderSampler(sampling_strategy='majority',  )\n",
    "            X_train, y_train = under.fit_resample(X_train, y_train)\n",
    "\n",
    "            #standard the variables\n",
    "            prep = StandardScaler()\n",
    "            prep.fit(X_train)\n",
    "\n",
    "            #perform a grid search for the best hyperparameters \n",
    "            best = GridSearchCV(clf, parameters, cv=gskf, scoring=(make_scorer(perf)))\n",
    "            best.fit(prep.transform(X_train), y_train)\n",
    "\n",
    "            #store the results\n",
    "            y_pred = [*y_pred, *(best.predict(prep.transform(X_test)))] \n",
    "            y_true =  [*y_true, *y_test] \n",
    "\n",
    "            #calculate recall metric \n",
    "            score[algorithm].append(recall_score(y_true, y_pred, labels = [0,1], average = None))\n",
    "\n",
    "            #calculate area under roc curve\n",
    "            aucscore = roc_auc_score(y_test, (best.predict_proba(prep.transform(X_test)))[:, 1])\n",
    "            auc_score[algorithm].append(aucscore)\n",
    "\n",
    "\n",
    "#write a csv with auc values            \n",
    "auc_score = pd.DataFrame.from_dict(auc_score)  \n",
    "auc_score.to_csv('hosp1_auc_gb.csv')\n",
    "\n",
    "#write a csv with recall values  \n",
    "recall_svm = pd.DataFrame(np.vstack(score['GB']))\n",
    "recall_svm.to_csv('hosp1_recall_gb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bp\n",
      "testando\n",
      "testando\n",
      "testando\n",
      "testando\n",
      "testando\n",
      "testando\n",
      "testando\n",
      "testando\n",
      "testando\n",
      "testando\n"
     ]
    }
   ],
   "source": [
    "#hosp2\n",
    "data = pd.read_csv(\"hosp2.csv\")\n",
    "\n",
    "X = data.drop(columns = [\"Severity\"])\n",
    "y = data.Severity\n",
    "\n",
    "#isolate the target variable \n",
    "X = data.drop(columns = [\"Severity\"])\n",
    "y = data.Severity\n",
    "\n",
    "#sets 3 folders to select the best hyper-parameters by cross validation within the grid search \n",
    "gskf = StratifiedKFold(n_splits=3, shuffle=True, random_state=17) \n",
    "\n",
    "#sets balanced accuracy to choose the best hyper-parameters within the grid search\n",
    "perf = balanced_accuracy_score\n",
    "\n",
    "#sets 10 folders for cross validation \n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=17) \n",
    "\n",
    "#will store each recall value\n",
    "score = {}\n",
    "for algorithm in algorithms.keys():\n",
    "    score[algorithm] = []\n",
    "\n",
    "#will store each auc value    \n",
    "auc_score = {}\n",
    "for algorithm in algorithms.keys():\n",
    "    auc_score[algorithm] = []\n",
    "    \n",
    "#for each algorithm and its dictionary of hyperparameters to be tested\n",
    "for algorithm, (clf, parameters) in algorithms.items():\n",
    "\n",
    "    #for each of the 10 folds      \n",
    "    for train, test in kf.split(X, y):\n",
    "        \n",
    "        #splits data into training and testing\n",
    "        X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "        y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "\n",
    "        #will store the y_predicted and y_true\n",
    "        y_pred = [] \n",
    "        y_true =  [] \n",
    "\n",
    "        #as the classes are umbalanced randomly undersampling the majority class repeating 10 times to avoid bias \n",
    "        for j in range(0,10):\n",
    "\n",
    "            #impute missing values with the mean of the 3 nearest neighbors\n",
    "            imputer = KNNImputer(n_neighbors=3)\n",
    "            imputer.fit(X_train)\n",
    "            X_train = imputer.transform(X_train)\n",
    "            X_test = imputer.transform(X_test)\n",
    "\n",
    "            #balance the classes by randomly undersampling the majority class\n",
    "            under = RandomUnderSampler(sampling_strategy='majority',  )\n",
    "            X_train, y_train = under.fit_resample(X_train, y_train)\n",
    "\n",
    "            #standard the variables\n",
    "            prep = StandardScaler()\n",
    "            prep.fit(X_train)\n",
    "\n",
    "            #perform a grid search for the best hyperparameters \n",
    "            best = GridSearchCV(clf, parameters, cv=gskf, scoring=(make_scorer(perf)))\n",
    "            best.fit(prep.transform(X_train), y_train)\n",
    "\n",
    "            #store the results\n",
    "            y_pred = [*y_pred, *(best.predict(prep.transform(X_test)))] \n",
    "            y_true =  [*y_true, *y_test] \n",
    "\n",
    "            #calculate recall metric \n",
    "            score[algorithm].append(recall_score(y_true, y_pred, labels = [0,1], average = None))\n",
    "\n",
    "            #calculate area under roc curve\n",
    "            aucscore = roc_auc_score(y_test, (best.predict_proba(prep.transform(X_test)))[:, 1])\n",
    "            auc_score[algorithm].append(aucscore)\n",
    "\n",
    "#write a csv with auc values               \n",
    "auc_score = pd.DataFrame.from_dict(auc_score)  \n",
    "auc_score.to_csv('hosp2_auc_gb.csv')\n",
    "\n",
    "#write a csv with recall values   \n",
    "recall_svm = pd.DataFrame(np.vstack(score['GB']))\n",
    "recall_svm.to_csv('hosp2_recall_gb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hosp3\n",
    "\n",
    "data = pd.read_csv(\"hosp3.csv\")\n",
    "X = data.drop(columns = [\"Severity\"])\n",
    "y = data.Severity\n",
    "\n",
    "#3 pastas para escolha dos melhores parâmetros\n",
    "gskf = StratifiedKFold(n_splits=3, shuffle=True, random_state=17) \n",
    "#escolha dos melhores parâmetros por acurácia balanceada\n",
    "perf = balanced_accuracy_score\n",
    "#validação cruzada com 10 pastas\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=17) \n",
    "\n",
    "#will store each recall value\n",
    "score = {}\n",
    "for algorithm in algorithms.keys():\n",
    "    score[algorithm] = []\n",
    "\n",
    "#will store each auc value    \n",
    "auc_score = {}\n",
    "for algorithm in algorithms.keys():\n",
    "    auc_score[algorithm] = []\n",
    "    \n",
    "#for each algorithm and its dictionary of hyperparameters to be tested\n",
    "for algorithm, (clf, parameters) in algorithms.items():\n",
    "\n",
    "        #for each of the 10 folds      \n",
    "        for train, test in kf.split(X, y):\n",
    "            \n",
    "        #splits data into training and testing\n",
    "        X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "        y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "\n",
    "        #will store the y_predicted and y_true\n",
    "        y_pred = [] \n",
    "        y_true =  [] \n",
    "        \n",
    "        #impute missing values with the mean of the 3 nearest neighbors\n",
    "        imputer = KNNImputer(n_neighbors=3)\n",
    "        imputer.fit(X_train)\n",
    "        X_train = imputer.transform(X_train)\n",
    "        X_test = imputer.transform(X_test)\n",
    "\n",
    "        #standard the variables\n",
    "        prep = StandardScaler()\n",
    "        prep.fit(X_train)\n",
    "\n",
    "        #perform a grid search for the best hyperparameters \n",
    "        best = GridSearchCV(clf, parameters, cv=gskf, scoring=(make_scorer(perf)))\n",
    "        best.fit(prep.transform(X_train), y_train)\n",
    "\n",
    "        #store the results\n",
    "        y_pred = [*y_pred, *(best.predict(prep.transform(X_test)))] \n",
    "        y_true =  [*y_true, *y_test] \n",
    "\n",
    "        #calculate recall metric \n",
    "        score[algorithm].append(recall_score(y_true, y_pred, labels = [0,1], average = None))\n",
    "\n",
    "        #calculate area under roc curve\n",
    "        aucscore = roc_auc_score(y_test, (best.predict_proba(prep.transform(X_test)))[:, 1])\n",
    "        auc_score[algorithm].append(aucscore)\n",
    "\n",
    "\n",
    "#write a csv with auc values         \n",
    "auc_score = pd.DataFrame.from_dict(auc_score)  \n",
    "auc_score.to_csv('hosp3_auc_gb.csv')\n",
    "\n",
    "#write a csv with recall values \n",
    "recall_svm = pd.DataFrame(np.vstack(score['GB']))\n",
    "recall_svm.to_csv('hosp3_recall_gb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hosp4\n",
    "\n",
    "data = pd.read_csv(\"hosp4.csv\")\n",
    "X = data.drop(columns = [\"Severity\"])\n",
    "y = data.Severity\n",
    "\n",
    "#3 pastas para escolha dos melhores parâmetros\n",
    "gskf = StratifiedKFold(n_splits=3, shuffle=True, random_state=17) \n",
    "#escolha dos melhores parâmetros por acurácia balanceada\n",
    "perf = balanced_accuracy_score\n",
    "#validação cruzada com 10 pastas\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=17) \n",
    "\n",
    "#will store each recall value\n",
    "score = {}\n",
    "for algorithm in algorithms.keys():\n",
    "    score[algorithm] = []\n",
    "\n",
    "#will store each auc value    \n",
    "auc_score = {}\n",
    "for algorithm in algorithms.keys():\n",
    "    auc_score[algorithm] = []\n",
    "    \n",
    "#for each algorithm and its dictionary of hyperparameters to be tested\n",
    "for algorithm, (clf, parameters) in algorithms.items():\n",
    "\n",
    "        #for each of the 10 folds      \n",
    "        for train, test in kf.split(X, y):\n",
    "            \n",
    "        #splits data into training and testing\n",
    "        X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "        y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "\n",
    "        #will store the y_predicted and y_true\n",
    "        y_pred = [] \n",
    "        y_true =  [] \n",
    "        \n",
    "        #as the classes are umbalanced randomly undersampling the majority class repeating 10 times to avoid bias         \n",
    "        for j in range(0,10):\n",
    "\n",
    "            #impute missing values with the mean of the 3 nearest neighbors\n",
    "            imputer = KNNImputer(n_neighbors=3)\n",
    "            imputer.fit(X_train)\n",
    "            X_train = imputer.transform(X_train)\n",
    "            X_test = imputer.transform(X_test)\n",
    "\n",
    "            #balance the classes by randomly undersampling the majority class\n",
    "            under = RandomUnderSampler(sampling_strategy='majority',  )\n",
    "            X_train, y_train = under.fit_resample(X_train, y_train)\n",
    "\n",
    "            #standard the variables\n",
    "            prep = StandardScaler()\n",
    "            prep.fit(X_train)\n",
    "\n",
    "            #perform a grid search for the best hyperparameters \n",
    "            best = GridSearchCV(clf, parameters, cv=gskf, scoring=(make_scorer(perf)))\n",
    "            best.fit(prep.transform(X_train), y_train)\n",
    "\n",
    "            #store the results\n",
    "            y_pred = [*y_pred, *(best.predict(prep.transform(X_test)))] \n",
    "            y_true =  [*y_true, *y_test] \n",
    "\n",
    "            #calculate recall metric \n",
    "            score[algorithm].append(recall_score(y_true, y_pred, labels = [0,1], average = None))\n",
    "\n",
    "            #calculate area under roc curve\n",
    "            aucscore = roc_auc_score(y_test, (best.predict_proba(prep.transform(X_test)))[:, 1])\n",
    "            auc_score[algorithm].append(aucscore)\n",
    "\n",
    "#write a csv with auc values               \n",
    "auc_score = pd.DataFrame.from_dict(auc_score)  \n",
    "auc_score.to_csv('hosp4_auc_gb.csv')\n",
    "\n",
    "#write a csv with recall values   \n",
    "recall_svm = pd.DataFrame(np.vstack(score['GB']))\n",
    "recall_svm.to_csv('hosp4_recall_gb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hosp5\n",
    "\n",
    "data = pd.read_csv(\"hosp5.csv\")\n",
    "X = data.drop(columns = [\"Severity\"])\n",
    "y = data.Severity\n",
    "\n",
    "#3 pastas para escolha dos melhores parâmetros\n",
    "gskf = StratifiedKFold(n_splits=3, shuffle=True, random_state=17) \n",
    "#escolha dos melhores parâmetros por acurácia balanceada\n",
    "perf = balanced_accuracy_score\n",
    "#validação cruzada com 10 pastas\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=17) \n",
    "\n",
    "#will store each recall value\n",
    "score = {}\n",
    "for algorithm in algorithms.keys():\n",
    "    score[algorithm] = []\n",
    "\n",
    "#will store each auc value    \n",
    "auc_score = {}\n",
    "for algorithm in algorithms.keys():\n",
    "    auc_score[algorithm] = []\n",
    "    \n",
    "#for each algorithm and its dictionary of hyperparameters to be tested\n",
    "for algorithm, (clf, parameters) in algorithms.items():\n",
    "\n",
    "        #for each of the 10 folds      \n",
    "        for train, test in kf.split(X, y):\n",
    "            \n",
    "        #splits data into training and testing\n",
    "        X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "        y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "\n",
    "        #will store the y_predicted and y_true\n",
    "        y_pred = [] \n",
    "        y_true =  [] \n",
    "\n",
    "        #impute missing values with the mean of the 3 nearest neighbors\n",
    "        imputer = KNNImputer(n_neighbors=3)\n",
    "        imputer.fit(X_train)\n",
    "        X_train = imputer.transform(X_train)\n",
    "        X_test = imputer.transform(X_test)\n",
    "\n",
    "        #balance the classes by randomly undersampling the majority class\n",
    "        under = RandomUnderSampler(sampling_strategy='majority',  )\n",
    "        X_train, y_train = under.fit_resample(X_train, y_train)\n",
    "\n",
    "        #standard the variables\n",
    "        prep = StandardScaler()\n",
    "        prep.fit(X_train)\n",
    "\n",
    "        #perform a grid search for the best hyperparameters \n",
    "        best = GridSearchCV(clf, parameters, cv=gskf, scoring=(make_scorer(perf)))\n",
    "        best.fit(prep.transform(X_train), y_train)\n",
    "\n",
    "        #store the results\n",
    "        y_pred = [*y_pred, *(best.predict(prep.transform(X_test)))] \n",
    "        y_true =  [*y_true, *y_test] \n",
    "\n",
    "        #calculate recall metrics\n",
    "        score[algorithm].append(recall_score(y_true, y_pred, labels = [0,1], average = None))\n",
    "\n",
    "        #calculate area under roc curve\n",
    "        aucscore = roc_auc_score(y_test, (best.predict_proba(prep.transform(X_test)))[:, 1])\n",
    "        auc_score[algorithm].append(aucscore)\n",
    "\n",
    "\n",
    "#write a csv with auc values   \n",
    "auc_score = pd.DataFrame.from_dict(auc_score)  \n",
    "auc_score.to_csv('hosp5_auc_gb.csv')\n",
    "\n",
    "#write a csv with recall values   \n",
    "recall_svm = pd.DataFrame(np.vstack(score['GB']))\n",
    "recall_svm.to_csv('hosp5_recall_gb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#algoritmos\n",
    "algorithms = {\"RF\" : (RandomForestClassifier(random_state=0), \n",
    "                      {\"n_estimators\": [100,200,500], \"max_depth\": [4,6,10],\n",
    "                       \"max_features\":(\"auto\", \"sqrt\", \"log2\")})}\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sirio\n",
      "testando\n",
      "testando\n",
      "testando\n",
      "testando\n",
      "testando\n",
      "testando\n",
      "testando\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-98009486dc7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;31m#faz a busca pelos pelos melhores parâmetros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgskf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mbest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;31m#armazena os resultados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    807\u001b[0m                                    (split_idx, (train, test)) in product(\n\u001b[1;32m    808\u001b[0m                                    \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                                    enumerate(cv.split(X, y, groups))))\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    391\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 393\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         indices = _generate_sample_indices(tree.random_state, n_samples,\n\u001b[0;32m--> 156\u001b[0;31m                                            n_samples_bootstrap)\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0msample_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0msample_counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_generate_sample_indices\u001b[0;34m(random_state, n_samples, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    119\u001b[0m     Private function used to _parallel_build_trees function.\"\"\"\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mrandom_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0msample_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples_bootstrap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_random_state\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmtrand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_mt19937.pyx\u001b[0m in \u001b[0;36mnumpy.random._mt19937.MT19937.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#hosp1\n",
    "\n",
    "data = pd.read_csv(\"hosp1.csv\")\n",
    "X = data.drop(columns = [\"Severity\"])\n",
    "y = data.Severity\n",
    "print('hosp1')\n",
    "\n",
    "#3 pastas para escolha dos melhores parâmetros\n",
    "gskf = StratifiedKFold(n_splits=3, shuffle=True, random_state=17) \n",
    "#escolha dos melhores parâmetros por acurácia balanceada\n",
    "perf = balanced_accuracy_score\n",
    "#validação cruzada com 10 pastas\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=17) \n",
    "\n",
    "#will store each recall value\n",
    "score = {}\n",
    "for algorithm in algorithms.keys():\n",
    "    score[algorithm] = []\n",
    "\n",
    "#will store each auc value    \n",
    "auc_score = {}\n",
    "for algorithm in algorithms.keys():\n",
    "    auc_score[algorithm] = []\n",
    "    \n",
    "#for each algorithm and its dictionary of hyperparameters to be tested\n",
    "for algorithm, (clf, parameters) in algorithms.items():\n",
    "\n",
    "        #for each of the 10 folds      \n",
    "        for train, test in kf.split(X, y):\n",
    "            \n",
    "        #splits data into training and testing\n",
    "        X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "        y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "        print(\"testando\")\n",
    "\n",
    "        #will store the y_predicted and y_true\n",
    "        y_pred = [] \n",
    "        y_true =  [] \n",
    "        \n",
    "        #as the classes are umbalanced randomly undersampling the majority class repeating 10 times to avoid bias           \n",
    "        for j in range(0,10):\n",
    "\n",
    "            #impute missing values with the mean of the 3 nearest neighbors\n",
    "            imputer = KNNImputer(n_neighbors=3)\n",
    "            imputer.fit(X_train)\n",
    "            X_train = imputer.transform(X_train)\n",
    "            X_test = imputer.transform(X_test)\n",
    "\n",
    "            #balance the classes by randomly undersampling the majority class\n",
    "            under = RandomUnderSampler(sampling_strategy='majority',  )\n",
    "            X_train, y_train = under.fit_resample(X_train, y_train)\n",
    "        \n",
    "            #standard the variables\n",
    "            prep = StandardScaler()\n",
    "            prep.fit(X_train)\n",
    "\n",
    "            #perform a grid search for the best hyperparameters \n",
    "            best = GridSearchCV(clf, parameters, cv=gskf, scoring=(make_scorer(perf)))\n",
    "            best.fit(prep.transform(X_train), y_train)\n",
    "\n",
    "            #store the results\n",
    "            y_pred = [*y_pred, *(best.predict(prep.transform(X_test)))] \n",
    "            y_true =  [*y_true, *y_test] \n",
    "\n",
    "            #calculate recall metrics\n",
    "            score[algorithm].append(recall_score(y_true, y_pred, labels = [0,1], average = None))\n",
    "\n",
    "            #calculate area under roc curve\n",
    "            aucscore = roc_auc_score(y_test, (best.predict_proba(prep.transform(X_test)))[:, 1])\n",
    "            auc_score[algorithm].append(aucscore)\n",
    "\n",
    "#write a csv with auc values             \n",
    "auc_score = pd.DataFrame.from_dict(auc_score)  \n",
    "auc_score.to_csv('hosp1_auc_rf.csv')\n",
    "\n",
    "#write a csv with recall values \n",
    "recall_svm = pd.DataFrame(np.vstack(score['RF']))\n",
    "recall_svm.to_csv('hosp1_recall_rf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hosp2\n",
    "\n",
    "data = pd.read_csv(\"hosp2.csv\")\n",
    "X = data.drop(columns = [\"Severity\"])\n",
    "y = data.Severity\n",
    "print('hosp2')\n",
    "\n",
    "#3 pastas para escolha dos melhores parâmetros\n",
    "gskf = StratifiedKFold(n_splits=3, shuffle=True, random_state=17) \n",
    "#escolha dos melhores parâmetros por acurácia balanceada\n",
    "perf = balanced_accuracy_score\n",
    "#validação cruzada com 10 pastas\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=17) \n",
    "\n",
    "#will store each recall value\n",
    "score = {}\n",
    "for algorithm in algorithms.keys():\n",
    "    score[algorithm] = []\n",
    "\n",
    "#will store each auc value    \n",
    "auc_score = {}\n",
    "for algorithm in algorithms.keys():\n",
    "    auc_score[algorithm] = []\n",
    "    \n",
    "#for each algorithm and its dictionary of hyperparameters to be tested\n",
    "for algorithm, (clf, parameters) in algorithms.items():\n",
    "\n",
    "        #for each of the 10 folds      \n",
    "        for train, test in kf.split(X, y):\n",
    "            \n",
    "        #splits data into training and testing\n",
    "        X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "        y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "\n",
    "        #will store the y_predicted and y_true\n",
    "        y_pred = [] \n",
    "        y_true =  [] \n",
    "\n",
    "        #as the classes are umbalanced randomly undersampling the majority class repeating 10 times to avoid bias   \n",
    "        for j in range(0,10):\n",
    "\n",
    "            #impute missing values with the mean of the 3 nearest neighbors\n",
    "            imputer = KNNImputer(n_neighbors=3)\n",
    "            imputer.fit(X_train)\n",
    "            X_train = imputer.transform(X_train)\n",
    "            X_test = imputer.transform(X_test)\n",
    "\n",
    "            #balance the classes by randomly undersampling the majority class\n",
    "            under = RandomUnderSampler(sampling_strategy='majority',  )\n",
    "            X_train, y_train = under.fit_resample(X_train, y_train)\n",
    "    \n",
    "            #standard the variables\n",
    "            prep = StandardScaler()\n",
    "            prep.fit(X_train)\n",
    "\n",
    "            #perform a grid search for the best hyperparameters \n",
    "            best = GridSearchCV(clf, parameters, cv=gskf, scoring=(make_scorer(perf)))\n",
    "            best.fit(prep.transform(X_train), y_train)\n",
    "\n",
    "            #store the results\n",
    "            y_pred = [*y_pred, *(best.predict(prep.transform(X_test)))] \n",
    "            y_true =  [*y_true, *y_test] \n",
    "\n",
    "            #calculate recall metrics\n",
    "            score[algorithm].append(recall_score(y_true, y_pred, labels = [0,1], average = None))\n",
    "\n",
    "            #calculate area under roc curve\n",
    "            aucscore = roc_auc_score(y_test, (best.predict_proba(prep.transform(X_test)))[:, 1])\n",
    "            auc_score[algorithm].append(aucscore)\n",
    "\n",
    "#write a csv with auc values            \n",
    "auc_score = pd.DataFrame.from_dict(auc_score)  \n",
    "auc_score.to_csv('hosp2_auc_rf.csv')\n",
    "\n",
    "#write a csv with recall values\n",
    "recall_svm = pd.DataFrame(np.vstack(score['RF']))\n",
    "recall_svm.to_csv('hosp2_recall_rf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hosp3\n",
    "\n",
    "data = pd.read_csv(\"hosp3.csv\")\n",
    "X = data.drop(columns = [\"Severity\"])\n",
    "y = data.Severity\n",
    "print('hosp3')\n",
    "\n",
    "#3 pastas para escolha dos melhores parâmetros\n",
    "gskf = StratifiedKFold(n_splits=3, shuffle=True, random_state=17) \n",
    "#escolha dos melhores parâmetros por acurácia balanceada\n",
    "perf = balanced_accuracy_score\n",
    "#validação cruzada com 10 pastas\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=17) \n",
    "\n",
    "#will store each recall value\n",
    "score = {}\n",
    "for algorithm in algorithms.keys():\n",
    "    score[algorithm] = []\n",
    "\n",
    "#will store each auc value    \n",
    "auc_score = {}\n",
    "for algorithm in algorithms.keys():\n",
    "    auc_score[algorithm] = []\n",
    "    \n",
    "#for each algorithm and its dictionary of hyperparameters to be tested\n",
    "for algorithm, (clf, parameters) in algorithms.items():\n",
    "\n",
    "        #for each of the 10 folds      \n",
    "        for train, test in kf.split(X, y):\n",
    "            \n",
    "        #splits data into training and testing\n",
    "        X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "        y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "        print(\"testando\")\n",
    "\n",
    "        #will store the y_predicted and y_true\n",
    "        y_pred = [] \n",
    "        y_true =  [] \n",
    "\n",
    "        #impute missing values with the mean of the 3 nearest neighbors\n",
    "        imputer = KNNImputer(n_neighbors=3)\n",
    "        imputer.fit(X_train)\n",
    "        X_train = imputer.transform(X_train)\n",
    "        X_test = imputer.transform(X_test)\n",
    "\n",
    "        #standard the variables\n",
    "        prep = StandardScaler()\n",
    "        prep.fit(X_train)\n",
    "\n",
    "        #perform a grid search for the best hyperparameters \n",
    "        best = GridSearchCV(clf, parameters, cv=gskf, scoring=(make_scorer(perf)))\n",
    "        best.fit(prep.transform(X_train), y_train)\n",
    "\n",
    "        #store the results\n",
    "        y_pred = [*y_pred, *(best.predict(prep.transform(X_test)))] \n",
    "        y_true =  [*y_true, *y_test] \n",
    "\n",
    "        #calculate recall metrics\n",
    "        score[algorithm].append(recall_score(y_true, y_pred, labels = [0,1], average = None))\n",
    "\n",
    "        #calculate area under roc curve\n",
    "        aucscore = roc_auc_score(y_test, (best.predict_proba(prep.transform(X_test)))[:, 1])\n",
    "        auc_score[algorithm].append(aucscore)\n",
    "        \n",
    "#write a csv with auc values            \n",
    "auc_score = pd.DataFrame.from_dict(auc_score)  \n",
    "auc_score.to_csv('hosp3_auc_rf.csv')\n",
    "\n",
    "#write a csv with recall values\n",
    "recall_svm = pd.DataFrame(np.vstack(score['RF']))\n",
    "recall_svm.to_csv('hosp3_recall_rf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hosp4\n",
    "\n",
    "data = pd.read_csv(\"hosp4.csv\")\n",
    "X = data.drop(columns = [\"Severity\"])\n",
    "y = data.Severity\n",
    "print('hosp4')\n",
    "\n",
    "#3 pastas para escolha dos melhores parâmetros\n",
    "gskf = StratifiedKFold(n_splits=3, shuffle=True, random_state=17) \n",
    "#escolha dos melhores parâmetros por acurácia balanceada\n",
    "perf = balanced_accuracy_score\n",
    "#validação cruzada com 10 pastas\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=17) \n",
    "\n",
    "#will store each recall value\n",
    "score = {}\n",
    "for algorithm in algorithms.keys():\n",
    "    score[algorithm] = []\n",
    "\n",
    "#will store each auc value    \n",
    "auc_score = {}\n",
    "for algorithm in algorithms.keys():\n",
    "    auc_score[algorithm] = []\n",
    "    \n",
    "#for each algorithm and its dictionary of hyperparameters to be tested\n",
    "for algorithm, (clf, parameters) in algorithms.items():\n",
    "\n",
    "        #for each of the 10 folds      \n",
    "        for train, test in kf.split(X, y):\n",
    "            \n",
    "        #splits data into training and testing\n",
    "        X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "        y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "        print(\"testando\")\n",
    "\n",
    "        #will store the y_predicted and y_true\n",
    "        y_pred = [] \n",
    "        y_true =  [] \n",
    "\n",
    "        #as the classes are umbalanced randomly undersampling the majority class repeating 10 times to avoid bias   \n",
    "        for j in range(0,10):\n",
    "\n",
    "            #impute missing values with the mean of the 3 nearest neighbors\n",
    "            imputer = KNNImputer(n_neighbors=3)\n",
    "            imputer.fit(X_train)\n",
    "            X_train = imputer.transform(X_train)\n",
    "            X_test = imputer.transform(X_test)\n",
    "\n",
    "            #balance the classes by randomly undersampling the majority class\n",
    "            under = RandomUnderSampler(sampling_strategy='majority',   )\n",
    "            X_train, y_train = under.fit_resample(X_train, y_train)\n",
    "    \n",
    "            #standard the variables\n",
    "            prep = StandardScaler()\n",
    "            prep.fit(X_train)\n",
    "\n",
    "            #perform a grid search for the best hyperparameters \n",
    "            best = GridSearchCV(clf, parameters, cv=gskf, scoring=(make_scorer(perf)))\n",
    "            best.fit(prep.transform(X_train), y_train)\n",
    "\n",
    "            #store the results\n",
    "            y_pred = [*y_pred, *(best.predict(prep.transform(X_test)))] \n",
    "            y_true =  [*y_true, *y_test] \n",
    "\n",
    "            #calculate recall metrics\n",
    "            score[algorithm].append(recall_score(y_true, y_pred, labels = [0,1], average = None))\n",
    "\n",
    "            #calculate area under roc curve\n",
    "            aucscore = roc_auc_score(y_test, (best.predict_proba(prep.transform(X_test)))[:, 1])\n",
    "            auc_score[algorithm].append(aucscore)\n",
    "\n",
    "#write a csv with auc values             \n",
    "auc_score = pd.DataFrame.from_dict(auc_score)  \n",
    "auc_score.to_csv('hosp4_auc_rf.csv')\n",
    "\n",
    "#write a csv with recall values \n",
    "recall_svm = pd.DataFrame(np.vstack(score['RF']))\n",
    "recall_svm.to_csv('hosp4_recall_rf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hosp5\n",
    "data = pd.read_csv(\"hosp5.csv\")\n",
    "X = data.drop(columns = [\"Severity\"])\n",
    "y = data.Severity\n",
    "print('hosp5')\n",
    "\n",
    "#3 pastas para escolha dos melhores parâmetros\n",
    "gskf = StratifiedKFold(n_splits=3, shuffle=True, random_state=17) \n",
    "#escolha dos melhores parâmetros por acurácia balanceada\n",
    "perf = balanced_accuracy_score\n",
    "#validação cruzada com 10 pastas\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=17) \n",
    "\n",
    "#will store each recall value\n",
    "score = {}\n",
    "for algorithm in algorithms.keys():\n",
    "    score[algorithm] = []\n",
    "\n",
    "#will store each auc value    \n",
    "auc_score = {}\n",
    "for algorithm in algorithms.keys():\n",
    "    auc_score[algorithm] = []\n",
    "    \n",
    "#for each algorithm and its dictionary of hyperparameters to be tested\n",
    "for algorithm, (clf, parameters) in algorithms.items():\n",
    "\n",
    "        #for each of the 10 folds      \n",
    "        for train, test in kf.split(X, y):\n",
    "            \n",
    "        #splits data into training and testing\n",
    "        X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "        y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "        print(\"testando\")\n",
    "\n",
    "        #will store the y_predicted and y_true\n",
    "        y_pred = [] \n",
    "        y_true =  [] \n",
    "\n",
    "        #impute missing values with the mean of the 3 nearest neighbors\n",
    "        imputer = KNNImputer(n_neighbors=3)\n",
    "        imputer.fit(X_train)\n",
    "        X_train = imputer.transform(X_train)\n",
    "        X_test = imputer.transform(X_test)\n",
    "\n",
    "        #standard the variables\n",
    "        prep = StandardScaler()\n",
    "        prep.fit(X_train)\n",
    "\n",
    "        #perform a grid search for the best hyperparameters \n",
    "        best = GridSearchCV(clf, parameters, cv=gskf, scoring=(make_scorer(perf)))\n",
    "        best.fit(prep.transform(X_train), y_train)\n",
    "\n",
    "        #store the results\n",
    "        y_pred = [*y_pred, *(best.predict(prep.transform(X_test)))] \n",
    "        y_true =  [*y_true, *y_test] \n",
    "\n",
    "        #calculate recall metrics\n",
    "        score[algorithm].append(recall_score(y_true, y_pred, labels = [0,1], average = None))\n",
    "\n",
    "        #calculate area under roc curve\n",
    "        aucscore = roc_auc_score(y_test, (best.predict_proba(prep.transform(X_test)))[:, 1])\n",
    "        auc_score[algorithm].append(aucscore)\n",
    "\n",
    "#write a csv with auc values         \n",
    "auc_score = pd.DataFrame.from_dict(auc_score)  \n",
    "auc_score.to_csv('hosp5_auc_rf.csv')\n",
    "\n",
    "#write a csv with recall values \n",
    "recall_svm = pd.DataFrame(np.vstack(score['RF']))\n",
    "recall_svm.to_csv('hosp5_recall_rf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#algoritmos\n",
    "algorithms = {\n",
    "    \"SVM\": (SVC(probability= True), {\"C\": [1, 10, 100], \n",
    "                                     \"kernel\": (\"linear\", \"rbf\"), \"gamma\": ('scale', 'auto')})}\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hosp1\n",
    "\n",
    "data = pd.read_csv(\"hosp1.csv\")\n",
    "X = data.drop(columns = [\"Severity\"])\n",
    "y = data.Severity\n",
    "print('hosp1')\n",
    "\n",
    "#3 pastas para escolha dos melhores parâmetros\n",
    "gskf = StratifiedKFold(n_splits=3, shuffle=True, random_state=17) \n",
    "#escolha dos melhores parâmetros por acurácia balanceada\n",
    "perf = balanced_accuracy_score\n",
    "#validação cruzada com 10 pastas\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=17) \n",
    "\n",
    "#will store each recall value\n",
    "score = {}\n",
    "for algorithm in algorithms.keys():\n",
    "    score[algorithm] = []\n",
    "\n",
    "#will store each auc value    \n",
    "auc_score = {}\n",
    "for algorithm in algorithms.keys():\n",
    "    auc_score[algorithm] = []\n",
    "    \n",
    "#for each algorithm and its dictionary of hyperparameters to be tested\n",
    "for algorithm, (clf, parameters) in algorithms.items():\n",
    "\n",
    "        #for each of the 10 folds      \n",
    "        for train, test in kf.split(X, y):\n",
    "            \n",
    "        #splits data into training and testing\n",
    "        X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "        y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "        print(\"testando\")\n",
    "\n",
    "        #will store the y_predicted and y_true\n",
    "        y_pred = [] \n",
    "        y_true =  [] \n",
    "\n",
    "        #as the classes are umbalanced randomly undersampling the majority class repeating 10 times to avoid bias           \n",
    "        for j in range(0,10):\n",
    "\n",
    "            #impute missing values with the mean of the 3 nearest neighbors\n",
    "            imputer = KNNImputer(n_neighbors=3)\n",
    "            imputer.fit(X_train)\n",
    "            X_train = imputer.transform(X_train)\n",
    "            X_test = imputer.transform(X_test)\n",
    "\n",
    "            #balance the classes by randomly undersampling the majority class\n",
    "            under = RandomUnderSampler(sampling_strategy='majority',  )\n",
    "            X_train, y_train = under.fit_resample(X_train, y_train)\n",
    "        \n",
    "            #standard the variables\n",
    "            prep = StandardScaler()\n",
    "            prep.fit(X_train)\n",
    "\n",
    "            #perform a grid search for the best hyperparameters \n",
    "            best = GridSearchCV(clf, parameters, cv=gskf, scoring=(make_scorer(perf)))\n",
    "            best.fit(prep.transform(X_train), y_train)\n",
    "\n",
    "            #store the results\n",
    "            y_pred = [*y_pred, *(best.predict(prep.transform(X_test)))] \n",
    "            y_true =  [*y_true, *y_test] \n",
    "\n",
    "            #calculate recall metrics\n",
    "            score[algorithm].append(recall_score(y_true, y_pred, labels = [0,1], average = None))\n",
    "\n",
    "            #calculate area under roc curve\n",
    "            aucscore = roc_auc_score(y_test, (best.predict_proba(prep.transform(X_test)))[:, 1])\n",
    "            auc_score[algorithm].append(aucscore)\n",
    "\n",
    "#write a csv with auc values             \n",
    "auc_score = pd.DataFrame.from_dict(auc_score)  \n",
    "auc_score.to_csv('hosp1_auc_svm.csv')\n",
    "\n",
    "#write a csv with recall values \n",
    "recall_svm = pd.DataFrame(np.vstack(score['SVM']))\n",
    "recall_svm.to_csv('hosp1_recall_svm.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hosp2\n",
    "\n",
    "data = pd.read_csv(\"hosp2.csv\")\n",
    "X = data.drop(columns = [\"Severity\"])\n",
    "y = data.Severity\n",
    "print('hosp2')\n",
    "\n",
    "#3 pastas para escolha dos melhores parâmetros\n",
    "gskf = StratifiedKFold(n_splits=3, shuffle=True, random_state=17) \n",
    "#escolha dos melhores parâmetros por acurácia balanceada\n",
    "perf = balanced_accuracy_score\n",
    "#validação cruzada com 10 pastas\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=17) \n",
    "\n",
    "#will store each recall value\n",
    "score = {}\n",
    "for algorithm in algorithms.keys():\n",
    "    score[algorithm] = []\n",
    "\n",
    "#will store each auc value    \n",
    "auc_score = {}\n",
    "for algorithm in algorithms.keys():\n",
    "    auc_score[algorithm] = []\n",
    "    \n",
    "#for each algorithm and its dictionary of hyperparameters to be tested\n",
    "for algorithm, (clf, parameters) in algorithms.items():\n",
    "\n",
    "        #for each of the 10 folds      \n",
    "        for train, test in kf.split(X, y):\n",
    "            \n",
    "        #splits data into training and testing\n",
    "        X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "        y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "        print(\"testando\")\n",
    "\n",
    "        #will store the y_predicted and y_true\n",
    "        y_pred = [] \n",
    "        y_true =  [] \n",
    "\n",
    "        #as the classes are umbalanced randomly undersampling the majority class repeating 10 times to avoid bias   \n",
    "        for j in range(0,10):\n",
    "\n",
    "            #impute missing values with the mean of the 3 nearest neighbors\n",
    "            imputer = KNNImputer(n_neighbors=3)\n",
    "            imputer.fit(X_train)\n",
    "            X_train = imputer.transform(X_train)\n",
    "            X_test = imputer.transform(X_test)\n",
    "\n",
    "            #balance the classes by randomly undersampling the majority class\n",
    "            under = RandomUnderSampler(sampling_strategy='majority',  )\n",
    "            X_train, y_train = under.fit_resample(X_train, y_train)\n",
    "    \n",
    "            #standard the variables\n",
    "            prep = StandardScaler()\n",
    "            prep.fit(X_train)\n",
    "\n",
    "            #perform a grid search for the best hyperparameters \n",
    "            best = GridSearchCV(clf, parameters, cv=gskf, scoring=(make_scorer(perf)))\n",
    "            best.fit(prep.transform(X_train), y_train)\n",
    "\n",
    "            #store the results\n",
    "            y_pred = [*y_pred, *(best.predict(prep.transform(X_test)))] \n",
    "            y_true =  [*y_true, *y_test] \n",
    "\n",
    "            #calculate recall metrics\n",
    "            score[algorithm].append(recall_score(y_true, y_pred, labels = [0,1], average = None))\n",
    "\n",
    "            #calculate area under roc curve\n",
    "            aucscore = roc_auc_score(y_test, (best.predict_proba(prep.transform(X_test)))[:, 1])\n",
    "            auc_score[algorithm].append(aucscore)\n",
    "\n",
    "#write a csv with auc values             \n",
    "auc_score = pd.DataFrame.from_dict(auc_score)  \n",
    "auc_score.to_csv('hosp2_auc_svm.csv')\n",
    "\n",
    "#write a csv with recall values \n",
    "recall_svm = pd.DataFrame(np.vstack(score['SVM']))\n",
    "recall_svm.to_csv('hosp2_recall_svm.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hosp3\n",
    "\n",
    "data = pd.read_csv(\"hosp3.csv\")\n",
    "X = data.drop(columns = [\"Severity\"])\n",
    "y = data.Severity\n",
    "print('hosp3')\n",
    "\n",
    "#3 pastas para escolha dos melhores parâmetros\n",
    "gskf = StratifiedKFold(n_splits=3, shuffle=True, random_state=17) \n",
    "#escolha dos melhores parâmetros por acurácia balanceada\n",
    "perf = balanced_accuracy_score\n",
    "#validação cruzada com 10 pastas\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=17) \n",
    "\n",
    "#will store each recall value\n",
    "score = {}\n",
    "for algorithm in algorithms.keys():\n",
    "    score[algorithm] = []\n",
    "\n",
    "#will store each auc value    \n",
    "auc_score = {}\n",
    "for algorithm in algorithms.keys():\n",
    "    auc_score[algorithm] = []\n",
    "    \n",
    "#for each algorithm and its dictionary of hyperparameters to be tested\n",
    "for algorithm, (clf, parameters) in algorithms.items():\n",
    "\n",
    "        #for each of the 10 folds      \n",
    "        for train, test in kf.split(X, y):\n",
    "            \n",
    "        #splits data into training and testing\n",
    "        X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "        y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "        print(\"testando\")\n",
    "\n",
    "        #will store the y_predicted and y_true\n",
    "        y_pred = [] \n",
    "        y_true =  [] \n",
    "\n",
    "        #impute missing values with the mean of the 3 nearest neighbors\n",
    "        imputer = KNNImputer(n_neighbors=3)\n",
    "        imputer.fit(X_train)\n",
    "        X_train = imputer.transform(X_train)\n",
    "        X_test = imputer.transform(X_test)\n",
    "\n",
    "        #standard the variables\n",
    "        prep = StandardScaler()\n",
    "        prep.fit(X_train)\n",
    "\n",
    "        #perform a grid search for the best hyperparameters \n",
    "        best = GridSearchCV(clf, parameters, cv=gskf, scoring=(make_scorer(perf)))\n",
    "        best.fit(prep.transform(X_train), y_train)\n",
    "\n",
    "        #store the results\n",
    "        y_pred = [*y_pred, *(best.predict(prep.transform(X_test)))] \n",
    "        y_true =  [*y_true, *y_test] \n",
    "\n",
    "        #calculate recall metrics\n",
    "        score[algorithm].append(recall_score(y_true, y_pred, labels = [0,1], average = None))\n",
    "\n",
    "        #calculate area under roc curve\n",
    "        aucscore = roc_auc_score(y_test, (best.predict_proba(prep.transform(X_test)))[:, 1])\n",
    "        auc_score[algorithm].append(aucscore)\n",
    "\n",
    "#write a csv with auc values            \n",
    "auc_score = pd.DataFrame.from_dict(auc_score)  \n",
    "auc_score.to_csv('hosp3_auc_svm.csv')\n",
    "\n",
    "#write a csv with recall values\n",
    "recall_svm = pd.DataFrame(np.vstack(score['SVM']))\n",
    "recall_svm.to_csv('hosp3_recall_svm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hosp4\n",
    "\n",
    "data = pd.read_csv(\"hosp4.csv\")\n",
    "X = data.drop(columns = [\"Severity\"])\n",
    "y = data.Severity\n",
    "print('hosp4')\n",
    "\n",
    "#3 pastas para escolha dos melhores parâmetros\n",
    "gskf = StratifiedKFold(n_splits=3, shuffle=True, random_state=17) \n",
    "#escolha dos melhores parâmetros por acurácia balanceada\n",
    "perf = balanced_accuracy_score\n",
    "#validação cruzada com 10 pastas\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=17) \n",
    "\n",
    "#will store each recall value\n",
    "score = {}\n",
    "for algorithm in algorithms.keys():\n",
    "    score[algorithm] = []\n",
    "\n",
    "#will store each auc value    \n",
    "auc_score = {}\n",
    "for algorithm in algorithms.keys():\n",
    "    auc_score[algorithm] = []\n",
    "    \n",
    "#for each algorithm and its dictionary of hyperparameters to be tested\n",
    "for algorithm, (clf, parameters) in algorithms.items():\n",
    "\n",
    "        #for each of the 10 folds      \n",
    "        for train, test in kf.split(X, y):\n",
    "            \n",
    "        #splits data into training and testing\n",
    "        X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "        y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "        print(\"testando\")\n",
    "\n",
    "        #will store the y_predicted and y_true\n",
    "        y_pred = [] \n",
    "        y_true =  [] \n",
    "\n",
    "        #as the classes are umbalanced randomly undersampling the majority class repeating 10 times to avoid bias   \n",
    "        for j in range(0,10):\n",
    "\n",
    "            #impute missing values with the mean of the 3 nearest neighbors\n",
    "            imputer = KNNImputer(n_neighbors=3)\n",
    "            imputer.fit(X_train)\n",
    "            X_train = imputer.transform(X_train)\n",
    "            X_test = imputer.transform(X_test)\n",
    "\n",
    "            #balance the classes by randomly undersampling the majority class\n",
    "            under = RandomUnderSampler(sampling_strategy='majority',   )\n",
    "            X_train, y_train = under.fit_resample(X_train, y_train)\n",
    "    \n",
    "            #standard the variables\n",
    "            prep = StandardScaler()\n",
    "            prep.fit(X_train)\n",
    "\n",
    "            #perform a grid search for the best hyperparameters \n",
    "            best = GridSearchCV(clf, parameters, cv=gskf, scoring=(make_scorer(perf)))\n",
    "            best.fit(prep.transform(X_train), y_train)\n",
    "\n",
    "            #store the results\n",
    "            y_pred = [*y_pred, *(best.predict(prep.transform(X_test)))] \n",
    "            y_true =  [*y_true, *y_test] \n",
    "\n",
    "            #calculate recall metrics\n",
    "            score[algorithm].append(recall_score(y_true, y_pred, labels = [0,1], average = None))\n",
    "\n",
    "            #calculate area under roc curve\n",
    "            aucscore = roc_auc_score(y_test, (best.predict_proba(prep.transform(X_test)))[:, 1])\n",
    "            auc_score[algorithm].append(aucscore)\n",
    "\n",
    "#write a csv with auc values\n",
    "auc_score = pd.DataFrame.from_dict(auc_score)  \n",
    "auc_score.to_csv('hosp4_auc_svm.csv')\n",
    "\n",
    "#write a csv with recall values\n",
    "recall_svm = pd.DataFrame(np.vstack(score['SVM']))\n",
    "recall_svm.to_csv('hosp4_recall_svm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hosp5\n",
    "\n",
    "data = pd.read_csv(\"hosp5.csv\")\n",
    "X = data.drop(columns = [\"Severity\"])\n",
    "y = data.Severity\n",
    "print('hosp5')\n",
    "\n",
    "#3 pastas para escolha dos melhores parâmetros\n",
    "gskf = StratifiedKFold(n_splits=3, shuffle=True, random_state=17) \n",
    "#escolha dos melhores parâmetros por acurácia balanceada\n",
    "perf = balanced_accuracy_score\n",
    "#validação cruzada com 10 pastas\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=17) \n",
    "\n",
    "#will store each recall value\n",
    "score = {}\n",
    "for algorithm in algorithms.keys():\n",
    "    score[algorithm] = []\n",
    "\n",
    "#will store each auc value    \n",
    "auc_score = {}\n",
    "for algorithm in algorithms.keys():\n",
    "    auc_score[algorithm] = []\n",
    "    \n",
    "#for each algorithm and its dictionary of hyperparameters to be tested\n",
    "for algorithm, (clf, parameters) in algorithms.items():\n",
    "\n",
    "        #for each of the 10 folds      \n",
    "        for train, test in kf.split(X, y):\n",
    "            \n",
    "        #splits data into training and testing\n",
    "        X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "        y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "        print(\"testando\")\n",
    "\n",
    "        #will store the y_predicted and y_true\n",
    "        y_pred = [] \n",
    "        y_true =  [] \n",
    "\n",
    "        #impute missing values with the mean of the 3 nearest neighbors\n",
    "        imputer = KNNImputer(n_neighbors=3)\n",
    "        imputer.fit(X_train)\n",
    "        X_train = imputer.transform(X_train)\n",
    "        X_test = imputer.transform(X_test)\n",
    "\n",
    "        #standard the variables\n",
    "        prep = StandardScaler()\n",
    "        prep.fit(X_train)\n",
    "\n",
    "        #perform a grid search for the best hyperparameters \n",
    "        best = GridSearchCV(clf, parameters, cv=gskf, scoring=(make_scorer(perf)))\n",
    "        best.fit(prep.transform(X_train), y_train)\n",
    "\n",
    "        #store the results\n",
    "        y_pred = [*y_pred, *(best.predict(prep.transform(X_test)))] \n",
    "        y_true =  [*y_true, *y_test] \n",
    "\n",
    "        #calculate recall metrics\n",
    "        score[algorithm].append(recall_score(y_true, y_pred, labels = [0,1], average = None))\n",
    "\n",
    "        #calculate area under roc curve\n",
    "        aucscore = roc_auc_score(y_test, (best.predict_proba(prep.transform(X_test)))[:, 1])\n",
    "        auc_score[algorithm].append(aucscore)\n",
    "\n",
    "#write a csv with auc values            \n",
    "auc_score = pd.DataFrame.from_dict(auc_score)  \n",
    "auc_score.to_csv('hosp5_auc_svm.csv')\n",
    "\n",
    "#write a csv with recall values\n",
    "recall_svm = pd.DataFrame(np.vstack(score['SVM']))\n",
    "recall_svm.to_csv('hosp5_recall_svm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hosp1 - mean\n",
    "\n",
    "#auc\n",
    "auc_s = pd.read_csv('hosp1_auc_svm.csv')\n",
    "auc_g = pd.read_csv('hosp1_auc_gb.csv')\n",
    "auc_r = pd.read_csv('hosp1_auc_rf.csv')\n",
    "\n",
    "#recall\n",
    "rf = pd.read_csv('hosp1_recall_rf.csv')\n",
    "gb = pd.read_csv('hosp1_recall_gb.csv')\n",
    "svm = pd.read_csv('hosp1_recall_svm.csv')\n",
    "\n",
    "column_names = [\"svm\", \"gb\", \"rf\"]\n",
    "\n",
    "#create a df with results\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "df.loc['auc'] = [auc_s['SVM'].mean(), auc_g['GB'].mean(), auc_r['RF'].mean()]\n",
    "df.loc['grave'] = [svm['1'].mean(), gb['1'].mean(), rf['1'].mean()]\n",
    "df.loc['n_grave'] = [svm['0'].mean(), gb['0'].mean(), rf['0'].mean()]\n",
    "\n",
    "#round to 3 decimal places and show results\n",
    "df = df.round(decimals=3)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hosp1 - std\n",
    "\n",
    "#auc\n",
    "auc_s = pd.read_csv('hosp1_auc_svm.csv')\n",
    "auc_g = pd.read_csv('hosp1_auc_gb.csv')\n",
    "auc_r = pd.read_csv('hosp1_auc_rf.csv')\n",
    "\n",
    "#recall\n",
    "rf = pd.read_csv('hosp1_recall_rf.csv')\n",
    "gb = pd.read_csv('hosp1_recall_gb.csv')\n",
    "svm = pd.read_csv('hosp1_recall_svm.csv')\n",
    "\n",
    "column_names = [\"svm\", \"gb\", \"rf\"]\n",
    "\n",
    "#create a df with results\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "df.loc['auc'] = [auc_s['SVM'].std(), auc_g['GB'].std(), auc_r['RF'].std()]\n",
    "df.loc['grave'] = [svm['1'].std(), gb['1'].std(), rf['1'].std()]\n",
    "df.loc['n_grave'] = [svm['0'].std(), gb['0'].std(), rf['0'].std()]\n",
    "\n",
    "\n",
    "#round to 3 decimal places and show results\n",
    "df = df.round(decimals=3)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hosp2 - mean\n",
    "\n",
    "#auc\n",
    "auc_s = pd.read_csv('hosp2_auc_svm.csv')\n",
    "auc_g = pd.read_csv('hosp2_auc_gb.csv')\n",
    "auc_r = pd.read_csv('hosp2_auc_rf.csv')\n",
    "\n",
    "#recall\n",
    "rf = pd.read_csv('hosp2_recall_rf.csv')\n",
    "gb = pd.read_csv('hosp2_recall_gb.csv')\n",
    "svm = pd.read_csv('hosp2_recall_svm.csv')\n",
    "\n",
    "column_names = [\"svm\", \"gb\", \"rf\"]\n",
    "\n",
    "#create a df with results\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "df.loc['auc'] = [auc_s['SVM'].mean(), auc_g['GB'].mean(), auc_r['RF'].mean()]\n",
    "df.loc['grave'] = [svm['1'].mean(), gb['1'].mean(), rf['1'].mean()]\n",
    "df.loc['n_grave'] = [svm['0'].mean(), gb['0'].mean(), rf['0'].mean()]\n",
    "\n",
    "\n",
    "#round to 3 decimal places and show results\n",
    "df = df.round(decimals=3)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hosp2 - std\n",
    "\n",
    "#auc\n",
    "auc_s = pd.read_csv('hosp2_auc_svm.csv')\n",
    "auc_g = pd.read_csv('hosp2_auc_gb.csv')\n",
    "auc_r = pd.read_csv('hosp2_auc_rf.csv')\n",
    "\n",
    "#recall\n",
    "rf = pd.read_csv('hosp2_recall_rf.csv')\n",
    "gb = pd.read_csv('hosp2_recall_gb.csv')\n",
    "svm = pd.read_csv('hosp2_recall_svm.csv')\n",
    "\n",
    "column_names = [\"svm\", \"gb\", \"rf\"]\n",
    "\n",
    "#create a df with results\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "df.loc['auc'] = [auc_s['SVM'].std(), auc_g['GB'].std(), auc_r['RF'].std()]\n",
    "df.loc['grave'] = [svm['1'].std(), gb['1'].std(), rf['1'].std()]\n",
    "df.loc['n_grave'] = [svm['0'].std(), gb['0'].std(), rf['0'].std()]\n",
    "\n",
    "#round to 3 decimal places and show results\n",
    "df = df.round(decimals=3)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hosp3 - mean\n",
    "\n",
    "#auc\n",
    "auc_s = pd.read_csv('hosp3_auc_svm.csv')\n",
    "auc_g = pd.read_csv('hosp3_auc_gb.csv')\n",
    "auc_r = pd.read_csv('hosp3_auc_rf.csv')\n",
    "\n",
    "# recall \n",
    "rf = pd.read_csv('hosp3_recall_rf.csv')\n",
    "gb = pd.read_csv('hosp3_recall_gb.csv')\n",
    "svm = pd.read_csv('hosp3_recall_svm.csv')\n",
    "\n",
    "column_names = [\"svm\", \"gb\", \"rf\"]\n",
    "\n",
    "#create a df with results\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "df.loc['auc'] = [auc_s['SVM'].mean(), auc_g['GB'].mean(), auc_r['RF'].mean()] \n",
    "df.loc['grave'] = [svm['1'].mean(), gb['1'].mean(), rf['1'].mean()] \n",
    "df.loc['n_grave'] = [svm['0'].mean(), gb['0'].mean(), rf['0'].mean()] \n",
    "\n",
    "#round to 3 decimal places and show results\n",
    "df = df.round(decimals=3)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hosp3 - std\n",
    "\n",
    "#auc\n",
    "auc_s = pd.read_csv('hosp3_auc_svm.csv')\n",
    "auc_g = pd.read_csv('hosp3_auc_gb.csv')\n",
    "auc_r = pd.read_csv('hosp3_auc_rf.csv')\n",
    "\n",
    "# recall \n",
    "rf = pd.read_csv('hosp3_recall_rf.csv')\n",
    "gb = pd.read_csv('hosp3_recall_gb.csv')\n",
    "svm = pd.read_csv('hosp3_recall_svm.csv')\n",
    "\n",
    "column_names = [\"svm\", \"gb\", \"rf\"]\n",
    "\n",
    "#create a df with results\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "df.loc['auc'] = [auc_s['SVM'].std(), auc_g['GB'].std(), auc_r['RF'].std()] \n",
    "df.loc['grave'] = [svm['1'].std(), gb['1'].std(), rf['1'].std()] \n",
    "df.loc['n_grave'] = [svm['0'].std(), gb['0'].std(), rf['0'].std()] \n",
    "\n",
    "#round to 3 decimal places and show results\n",
    "df = df.round(decimals=3)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hosp4 - mean\n",
    "\n",
    "#auc\n",
    "auc_s = pd.read_csv('hosp4_auc_svm.csv')\n",
    "auc_g = pd.read_csv('hosp4_auc_gb.csv')\n",
    "auc_r = pd.read_csv('hosp4_auc_rf.csv')\n",
    "\n",
    "# recall \n",
    "rf = pd.read_csv('hosp4_recall_rf.csv')\n",
    "gb = pd.read_csv('hosp4_recall_gb.csv')\n",
    "svm = pd.read_csv('hosp4_recall_svm.csv')\n",
    "\n",
    "column_names = [\"svm\", \"gb\", \"rf\"]\n",
    "\n",
    "#create a df with results\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "df.loc['auc'] = [auc_s['SVM'].mean(), auc_g['GB'].mean(), auc_r['RF'].mean()] \n",
    "df.loc['grave'] = [svm['1'].mean(), gb['1'].mean(), rf['1'].mean()] \n",
    "df.loc['n_grave'] = [svm['0'].mean(), gb['0'].mean(), rf['0'].mean()] \n",
    "\n",
    "#round to 3 decimal places and show results\n",
    "df = df.round(decimals=3)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hosp4 - std\n",
    "\n",
    "#auc\n",
    "auc_s = pd.read_csv('hosp4_auc_svm.csv')\n",
    "auc_g = pd.read_csv('hosp4_auc_gb.csv')\n",
    "auc_r = pd.read_csv('hosp4_auc_rf.csv')\n",
    "\n",
    "# recall \n",
    "rf = pd.read_csv('hosp4_recall_rf.csv')\n",
    "gb = pd.read_csv('hosp4_recall_gb.csv')\n",
    "svm = pd.read_csv('hosp4_recall_svm.csv')\n",
    "\n",
    "column_names = [\"svm\", \"gb\", \"rf\"]\n",
    "\n",
    "#create a df with results\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "df.loc['auc'] = [auc_s['SVM'].std(), auc_g['GB'].std(), auc_r['RF'].std()] \n",
    "df.loc['grave'] = [svm['1'].std(), gb['1'].std(), rf['1'].std()] \n",
    "df.loc['n_grave'] = [svm['0'].std(), gb['0'].std(), rf['0'].std()] \n",
    "\n",
    "#round to 3 decimal places and show results\n",
    "df = df.round(decimals=3)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hosp5 - mean\n",
    "\n",
    "#auc\n",
    "auc_s = pd.read_csv('hosp5_auc_svm.csv')\n",
    "auc_g = pd.read_csv('hosp5_auc_gb.csv')\n",
    "auc_r = pd.read_csv('hosp5_auc_rf.csv')\n",
    "\n",
    "# recall \n",
    "rf = pd.read_csv('hosp5_recall_rf.csv')\n",
    "gb = pd.read_csv('hosp5_recall_gb.csv')\n",
    "svm = pd.read_csv('hosp5_recall_svm.csv')\n",
    "\n",
    "column_names = [\"svm\", \"gb\", \"rf\"]\n",
    "\n",
    "#create a df with results\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "df.loc['auc'] = [auc_s['SVM'].mean(), auc_g['GB'].mean(), auc_r['RF'].mean()] \n",
    "df.loc['grave'] = [svm['1'].mean(), gb['1'].mean(), rf['1'].mean()] \n",
    "df.loc['n_grave'] = [svm['0'].mean(), gb['0'].mean(), rf['0'].mean()] \n",
    "\n",
    "#round to 3 decimal places and show results\n",
    "df = df.round(decimals=3)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hosp5 - std\n",
    "\n",
    "#auc\n",
    "auc_s = pd.read_csv('hosp5_auc_svm.csv')\n",
    "auc_g = pd.read_csv('hosp5_auc_gb.csv')\n",
    "auc_r = pd.read_csv('hosp5_auc_rf.csv')\n",
    "\n",
    "# recall \n",
    "rf = pd.read_csv('hosp5_recall_rf.csv')\n",
    "gb = pd.read_csv('hosp5_recall_gb.csv')\n",
    "svm = pd.read_csv('hosp5_recall_svm.csv')\n",
    "\n",
    "column_names = [\"svm\", \"gb\", \"rf\"]\n",
    "\n",
    "#create a df with results\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "df.loc['auc'] = [auc_s['SVM'].std(), auc_g['GB'].std(), auc_r['RF'].std()] \n",
    "df.loc['grave'] = [svm['1'].std(), gb['1'].std(), rf['1'].std()] \n",
    "df.loc['n_grave'] = [svm['0'].std(), gb['0'].std(), rf['0'].std()] \n",
    "\n",
    "#round to 3 decimal places and show results\n",
    "df = df.round(decimals=3)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
